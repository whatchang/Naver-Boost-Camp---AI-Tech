<!--
구조
*
    *
        * <br>
            &nbsp; - &nbsp; <br>
                &nbsp;&nbsp;&nbsp;&nbsp; ‣ &nbsp; <br>
                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; * &nbsp; <br>
-->

# Day 

## 목차 

1. [공부한 내용 정리](#1-공부한-내용-정리)

2. [진행중인 실험](#2-진행중인-실험)

3. [학습 회고](#3-학습-회고)

## 1. 공부한 내용 정리

없음

<br>

## 2. 진행중인 실험

[not in-batch, random sample(use elasticsearch) train 방식](https://github.com/boostcampaitech2/mrc-level2-nlp-04/issues/36) <- 왜 top - k에서 성능이 안 좋은 이유/원인 찾기

새로운 실험 - MRC reader model train시 context의 단어를 masking하여 훈력시키기

<br>

## 3. 학습 회고

not in-batch, random sample(use elasticsearch) train 방식 - 실험에서 왜 eval의 성능이 안 좋은지 원인을 찾아봤지만 결국 못 찾았다.

남은 시간이 별로 없었기 때문에 다음 실험으로 넣어갔고 이 MRC reader model train시 context의 단어를 masking하여 훈력시키는 실험은 팀원과 pair coding을 통해서 구현할 예정이다.

내일 오전부터 같이 구현하기로 했기 때문에 오늘 남은 시간에 자료 조사를 할 생각이다.


<br>